{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNOB78vrnPCHwT3DsIjRyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edanbave94/Deep_Learning/blob/main/DataPreparationRNN.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCl8721kvw2-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.utils import check_array\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    #y_true, y_pred = check_array(y_true, y_pred)\n",
        "\n",
        "    ## Note: does not handle mix 1d representation\n",
        "    #if _is_1d(y_true):\n",
        "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
        "\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "#split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)\n",
        "\n",
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def create_datasetMultipleTimesBackAhead(dataset, n_steps_out=1, n_steps_in = 1, overlap = 1):\n",
        "\tdataX, dataY = [], []\n",
        "\ttem = n_steps_in + n_steps_out - overlap\n",
        "\tfor i in range(int((len(dataset) - tem)/overlap)):\n",
        "\t\tstartx = i*overlap\n",
        "\t\tendx = startx + n_steps_in\n",
        "\t\tstarty = endx\n",
        "\t\tendy = endx + n_steps_out\n",
        "\t\ta = dataset[startx:endx, 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[starty:endy, 0])\n",
        "\treturn np.array(dataX), np.array(dataY)\n",
        "\n",
        "def PintaResultado(dataset,trainPredict,testPredict,look_back):\n",
        "\ttrainPredictPlot = np.empty_like(dataset)\n",
        "\ttrainPredictPlot[:, :] = np.nan\n",
        "\ttrainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\t# shift test predictions for plotting\n",
        "\ttestPredictPlot = np.empty_like(dataset+1)\n",
        "\ttestPredictPlot[:, :] = np.nan\n",
        "\tNtest = len(testPredict)\n",
        "\tNtestSpace = len(dataset)+1 - (len(trainPredict)+(look_back*2))\n",
        "\trestante = NtestSpace - Ntest\n",
        "\tprint(restante)\n",
        "\ttestPredictPlot[len(trainPredict)+(look_back*2):len(dataset)+1-restante, :] = testPredict\n",
        "\t#testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\t#testPredictPlot[len(dataset)-len(testPredict):len(dataset)+1, :] = testPredict\n",
        "\t# plot baseline and predictions\n",
        "\tplt.figure(figsize=(10,4))\n",
        "\tplt.plot(dataset,label='Original Time serie')\n",
        "\tplt.plot(trainPredictPlot,label='Training prediction')\n",
        "\tplt.plot(testPredictPlot,label='Test prediction')\n",
        "\tplt.legend()\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "def EstimaRMSE(model,X_train,X_test,y_train,y_test,scaler,look_back):\n",
        "\t# make predictions\n",
        "\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],look_back))\n",
        "\ttestPredict = model.predict(X_test.reshape(X_test.shape[0],look_back))\n",
        "\t# invert predictions\n",
        "\ttrainPredict = scaler.inverse_transform(trainPredict)\n",
        "\ttrainY = scaler.inverse_transform([y_train.flatten()])\n",
        "\ttestPredict = scaler.inverse_transform(testPredict)\n",
        "\ttestY = scaler.inverse_transform([y_test.flatten()])\n",
        "\t# calculate root mean squared error\n",
        "\ttrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "\tprint('Train Score: %.2f RMSE' % (trainScore))\n",
        "\ttestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "\tprint('Test Score: %.2f RMSE' % (testScore))\n",
        "\ttrainScoreMAPE = mean_absolute_percentage_error(trainY[0], trainPredict[:,0])\n",
        "\ttestScoreMAPE = mean_absolute_percentage_error(testY[0], testPredict[:,0])\n",
        "\tprint('Train Score: %.2f MAPE' % (trainScoreMAPE))\n",
        "\tprint('Test Score: %.2f MAPE' % (testScoreMAPE))\n",
        "\treturn trainPredict, testPredict\n",
        "\n",
        "def EstimaRMSE_RNN(model,X_train,X_test,y_train,y_test,scaler,look_back,n_steps):\n",
        "\t# make predictions\n",
        "\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],n_steps,look_back))\n",
        "\ttestPredict = model.predict(X_test.reshape(X_test.shape[0],n_steps,look_back))\n",
        "\t# invert predictions\n",
        "\ttrainPredict = scaler.inverse_transform(trainPredict)\n",
        "\ttrainY = scaler.inverse_transform([y_train.flatten()])\n",
        "\ttestPredict = scaler.inverse_transform(testPredict)\n",
        "\ttestY = scaler.inverse_transform([y_test.flatten()])\n",
        "\t# calculate root mean squared error\n",
        "\ttrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "\tprint('Train Score: %.2f RMSE' % (trainScore))\n",
        "\ttestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "\tprint('Test Score: %.2f RMSE' % (testScore))\n",
        "\ttrainScoreMAPE = mean_absolute_percentage_error(trainY[0], trainPredict[:,0])\n",
        "\ttestScoreMAPE = mean_absolute_percentage_error(testY[0], testPredict[:,0])\n",
        "\tprint('Train Score: %.2f MAPE' % (trainScoreMAPE))\n",
        "\tprint('Test Score: %.2f MAPE' % (testScoreMAPE))\n",
        "\treturn trainPredict, testPredict\n",
        "\n",
        "def EstimaRMSE_MultiStep(model,X_train,X_test,y_train,y_test,scaler,look_back,n_steps):\n",
        "\t# make predictions\n",
        "\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],look_back))\n",
        "\ttestPredict = []\n",
        "\tfor i in range(X_test.shape[0]):\n",
        "\t\ttemPredict = np.zeros([n_steps])\n",
        "\t\tfor j in range(n_steps):\n",
        "\t\t\tif j==0:\n",
        "\t\t\t\txtest = X_test[i,:]\n",
        "\t\t\telse:\n",
        "\t\t\t\txtest = np.concatenate((X_test[i,j:],temPredict[:j]))\n",
        "\t\t\ttemPredict[j] = model.predict(xtest.reshape(1,look_back))\n",
        "\t\ttestPredict.append(temPredict)\n",
        "\ttestPredict = np.array(testPredict)\n",
        "\ttestPredict = testPredict.flatten()\n",
        "\t# invert predictions\n",
        "\ttrainPredict = scaler.inverse_transform(trainPredict)\n",
        "\ttrainY = scaler.inverse_transform([y_train.flatten()])\n",
        "\ttestPredict = scaler.inverse_transform(testPredict.reshape(-1, 1))\n",
        "\ttestY = scaler.inverse_transform([y_test.flatten()])\n",
        "\t# calculate root mean squared error\n",
        "\ttrainScore = math.sqrt(mean_squared_error(trainY.reshape(-1, 1), trainPredict.reshape(-1, 1)))\n",
        "\tprint('Train Score: %.2f RMSE' % (trainScore))\n",
        "\ttestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "\tprint('Test Score: %.2f RMSE' % (testScore))\n",
        "\ttrainScoreMAPE = mean_absolute_percentage_error(trainY.reshape(-1, 1), trainPredict.reshape(-1, 1))\n",
        "\ttestScoreMAPE = mean_absolute_percentage_error(testY[0], testPredict[:,0])\n",
        "\tprint('Train Score: %.2f MAPE' % (trainScoreMAPE))\n",
        "\tprint('Test Score: %.2f MAPE' % (testScoreMAPE))\n",
        "\treturn trainPredict, testPredict\n",
        "\n",
        "def EstimaRMSE_MultiOuput(model,X_train,X_test,y_train,y_test,scaler,look_back):\n",
        "\t# make predictions\n",
        "\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],look_back))\n",
        "\ttestPredict = model.predict(X_test.reshape(X_test.shape[0],look_back))\n",
        "\t# invert predictions\n",
        "\ttrainPredict = scaler.inverse_transform(trainPredict.flatten().reshape(-1, 1))\n",
        "\ttrainY = scaler.inverse_transform([y_train.flatten()])\n",
        "\ttestPredict = scaler.inverse_transform(testPredict.flatten().reshape(-1, 1))\n",
        "\ttestY = scaler.inverse_transform([y_test.flatten()])\n",
        "\t# calculate root mean squared error\n",
        "\ttrainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "\tprint('Train Score: %.2f RMSE' % (trainScore))\n",
        "\ttestScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "\tprint('Test Score: %.2f RMSE' % (testScore))\n",
        "\ttrainScoreMAPE = mean_absolute_percentage_error(trainY[0], trainPredict[:,0])\n",
        "\ttestScoreMAPE = mean_absolute_percentage_error(testY[0], testPredict[:,0])\n",
        "\tprint('Train Score: %.2f MAPE' % (trainScoreMAPE))\n",
        "\tprint('Test Score: %.2f MAPE' % (testScoreMAPE))\n",
        "\treturn trainPredict, testPredict\n",
        "\n",
        "def EstimaRMSE_RNN_MultiStep(model,X_train,X_test,y_train,y_test,scaler,look_back,n_steps,flag):\n",
        "\t# make predictions\n",
        "\tif flag == 1:#multiple times set as features\n",
        "\t\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],1,look_back))\n",
        "\t\ttestPredict = []\n",
        "\t\tfor i in range(X_test.shape[0]):\n",
        "\t\t\ttemPredict = np.zeros([n_steps])\n",
        "\t\t\tfor j in range(n_steps):\n",
        "\t\t\t\tif j==0:\n",
        "\t\t\t\t\txtest = X_test[i,:]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\txtest = np.concatenate((X_test[i,j:],temPredict[:j]))\n",
        "\t\t\t\ttemPredict[j] = model.predict(xtest.reshape(1,1,look_back))\n",
        "\t\t\ttestPredict.append(temPredict)\n",
        "\t\ttestPredict = np.array(testPredict)\n",
        "\t\ttestPredict = testPredict.flatten()\n",
        "\telse: #multiple times set as times\n",
        "\t\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],look_back,1))\n",
        "\t\ttestPredict = []\n",
        "\t\tfor i in range(X_test.shape[0]):\n",
        "\t\t\ttemPredict = np.zeros([n_steps])\n",
        "\t\t\tfor j in range(n_steps):\n",
        "\t\t\t\tif j==0:\n",
        "\t\t\t\t\txtest = X_test[i,:]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\txtest = np.concatenate((X_test[i,j:],temPredict[:j]))\n",
        "\t\t\t\ttemPredict[j] = model.predict(xtest.reshape(1,look_back,1))\n",
        "\t\t\ttestPredict.append(temPredict)\n",
        "\t\ttestPredict = np.array(testPredict)\n",
        "\t\ttestPredict = testPredict.flatten()\n",
        "\n",
        "\t# invert predictions\n",
        "\ttrainPredict = scaler.inverse_transform(trainPredict.reshape(-1, 1))\n",
        "\ttrainY = scaler.inverse_transform(y_train)\n",
        "\ttestPredict = scaler.inverse_transform(testPredict.reshape(-1, 1))\n",
        "\ttestY = scaler.inverse_transform(y_test.flatten().reshape(-1, 1))\n",
        "\t# calculate root mean squared error\n",
        "\ttrainScore = math.sqrt(mean_squared_error(trainY.reshape(-1, 1), trainPredict.reshape(-1, 1)))\n",
        "\tprint('Train Score: %.2f RMSE' % (trainScore))\n",
        "\ttestScore = math.sqrt(mean_squared_error(testY.reshape(-1, 1), testPredict.reshape(-1, 1)))\n",
        "\tprint('Test Score: %.2f RMSE' % (testScore))\n",
        "\ttrainScoreMAPE = mean_absolute_percentage_error(trainY.reshape(-1, 1), trainPredict.reshape(-1, 1))\n",
        "\ttestScoreMAPE = mean_absolute_percentage_error(testY.reshape(-1, 1), testPredict.reshape(-1, 1))\n",
        "\tprint('Train Score: %.2f MAPE' % (trainScoreMAPE))\n",
        "\tprint('Test Score: %.2f MAPE' % (testScoreMAPE))\n",
        "\treturn trainPredict, testPredict\n",
        "\n",
        "def EstimaRMSE_RNN_MultiStepEncoDeco(model,X_train,X_test,y_train,y_test,scaler,look_back,n_steps):\n",
        "\t# make predictions\n",
        "\ttrainPredict = model.predict(X_train.reshape(X_train.shape[0],look_back,1))\n",
        "\ttrainPredict = trainPredict.flatten()\n",
        "\ttestPredict = model.predict(X_test.reshape(X_test.shape[0],look_back,1))\n",
        "\ttestPredict = testPredict.flatten()\n",
        "\t# invert predictions\n",
        "\ttrainPredict = scaler.inverse_transform(trainPredict.reshape(-1, 1))\n",
        "\ttrainY = scaler.inverse_transform(y_train.flatten().reshape(-1, 1))\n",
        "\ttestPredict = scaler.inverse_transform(testPredict.reshape(-1, 1))\n",
        "\ttestY = scaler.inverse_transform(y_test.flatten().reshape(-1, 1))\n",
        "\t# calculate root mean squared error\n",
        "\ttrainScore = math.sqrt(mean_squared_error(trainY.flatten().reshape(-1, 1), trainPredict.reshape(-1, 1)))\n",
        "\tprint('Train Score: %.2f RMSE' % (trainScore))\n",
        "\ttestScore = math.sqrt(mean_squared_error(testY.flatten().reshape(-1, 1), testPredict.reshape(-1, 1)))\n",
        "\tprint('Test Score: %.2f RMSE' % (testScore))\n",
        "\ttrainScoreMAPE = mean_absolute_percentage_error(trainY.flatten().reshape(-1, 1), trainPredict.reshape(-1, 1))\n",
        "\ttestScoreMAPE = mean_absolute_percentage_error(testY.flatten().reshape(-1, 1), testPredict.reshape(-1, 1))\n",
        "\tprint('Train Score: %.2f MAPE' % (trainScoreMAPE))\n",
        "\tprint('Test Score: %.2f MAPE' % (testScoreMAPE))\n",
        "\treturn trainPredict, testPredict\n",
        "\n",
        "def PlotValidationTimeSeries(datasetO):\n",
        "\tN=np.max(datasetO.index)\n",
        "\tfig, ax = plt.subplots(figsize=(10,7), sharex=True)\n",
        "\tdatasetO.plot(0,1,figsize=(10,4), ax=ax)\n",
        "\tax.axvspan(datasetO.index[0], datasetO.index[int(N*0.6)], color=sns.xkcd_rgb['grey'], alpha=0.5)\n",
        "\tax.axvspan(datasetO.index[int(N*0.6)], datasetO.index[int(N*0.8)],color=sns.xkcd_rgb['light blue'], alpha=0.5)\n",
        "\tax.axvspan(datasetO.index[int(N*0.8)], datasetO.index[N],color=sns.xkcd_rgb['light pink'], alpha=0.5)\n",
        "\tplt.text(datasetO.index[int(N*0.2)], 620, \"60% Training set\")\n",
        "\tplt.text(datasetO.index[int(N*0.62)], 620, \"20% Validation set\")\n",
        "\tplt.text(datasetO.index[int(N*0.82)], 620, \"20% Test set\")\n",
        "\tplt.legend().remove()\n",
        "\n",
        "def PlotCrossvalidationTS():\n",
        "\tn_datasets = 20\n",
        "\tplt.figure(figsize=(10,5))\n",
        "\tfor i in range(n_datasets):\n",
        "\t\ttexto = 'Split'+ ' ' + str(i+1)\n",
        "\t\tplt.text(-2,8-i*0.4,texto)\n",
        "\t\tplt.arrow(0, 8-i*0.4, 27, 0, alpha=0.3, head_width=0.1, head_length=0.5, fc='k', ec='k')\n",
        "\t\tm1 = np.arange(1,27)\n",
        "\t\ty = np.r_[np.zeros(i+6, dtype=int),np.ones(1,dtype=int),2*np.ones(19-i,dtype=int)]\n",
        "\t\tx2 = [8-i*0.4]*len(m1)\n",
        "\t\tplt.scatter(m1[:i+6], x2[:i+6] , color='b', alpha=0.5, s=70)\n",
        "\t\tplt.scatter(m1[i+6],  x2[i+6], color= 'r', alpha=0.5, s=70)\n",
        "\t\tplt.scatter(m1[i+7:], x2[i+7:], color ='grey', alpha=0.5, s=70)\n",
        "\tplt.text(28,8,'Time')\n",
        "\tplt.axis(\"off\")\n",
        "\tplt.show()\n",
        "\n",
        "def PlotCrossvalidationTS_Gap():\n",
        "\tn_datasets = 16\n",
        "\tplt.figure(figsize=(10,5))\n",
        "\tfor i in range(n_datasets):\n",
        "\t\ttexto = 'Split'+ ' ' +str(i+1)\n",
        "\t\tplt.text(-2,8-i*0.4,texto)\n",
        "\t\tplt.arrow(0, 8-i*0.4, 27, 0, alpha=0.3, head_width=0.1, head_length=0.5, fc='k', ec='k')\n",
        "\t\tm1 = np.arange(1,27)\n",
        "\t\ty = np.r_[np.zeros(i+6, dtype=int),np.ones(1,dtype=int),2*np.ones(19-i,dtype=int)]\n",
        "\t\tx2 = [8-i*0.4]*len(m1)\n",
        "\t\tplt.scatter(m1[:i+6], x2[:i+6] , color='b', alpha=0.5, s=70)\n",
        "\t\tplt.scatter(m1[i+6:i+10], x2[i+6:i+10], color ='grey', alpha=0.5, s=70)\n",
        "\t\tplt.scatter(m1[i+10],  x2[i+10], color= 'r', alpha=0.5, s=70)\n",
        "\t\tplt.scatter(m1[i+11:], x2[i+11:], color ='grey', alpha=0.5, s=70)\n",
        "\tplt.text(28,8,'Time')\n",
        "\tplt.axis(\"off\")\n",
        "\tplt.show()\n",
        "\n",
        "def DataPreparation(MVSeries,look_back,create_datasetMV):\n",
        "\tgroups = [0, 1, 2, 3, 5, 6, 7]\n",
        "\ttimes = MVSeries.shape[0]\n",
        "    # split into train and test sets\n",
        "\ttrain_size = int(times * 0.67)\n",
        "\ttest_size = times - train_size\n",
        "\ttrain, test = MVSeries[0:train_size,groups], MVSeries[train_size-look_back:times,groups]\n",
        "    # normalize the dataset\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\ttrainN = scaler.fit_transform(train)\n",
        "\ttestN = scaler.transform(test)\n",
        "\tX_train, y_train = create_datasetMV(trainN, look_back)\n",
        "\tX_test, y_test = create_datasetMV(testN, look_back)\n",
        "    # Defino un scaler sólo para polución\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler.fit(train[:,0].reshape(-1,1))\n",
        "\treturn X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def TrainModel(X_train,y_train,model):\n",
        "\n",
        "    Optimi = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(optimizer=Optimi,loss='mse',metrics=['mae'])\n",
        "    #-------------------------------------------------------------------------------------------------\n",
        "    #!rm -rf ./logs/\n",
        "    #log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "    #-------------------------------------------------------------------------------------------------\n",
        "    stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
        "    model.fit(X_train,y_train,epochs=20, validation_split=0.1, verbose=0, callbacks=[stop])\n",
        "    return model\n",
        "\n",
        "def Plot_Task2(mse):\n",
        "\tlook_back = range(1,6)\n",
        "\tplt.figure(figsize=(14,4))\n",
        "\t#plt.subplot(131)\n",
        "\tplt.plot(look_back,mse[0,:],label='RNN')\n",
        "\tplt.plot(look_back,mse[1,:],label='LSTM')\n",
        "\tplt.plot(look_back,mse[2,:],label='GRU')\n",
        "\tplt.xlabel('Number of lookbacks')\n",
        "\tplt.ylabel('RMSE')\n",
        "\tplt.legend()\n",
        "\tplt.grid()\n",
        "\t#---------------------------------------------------------\n",
        "\t#plt.title('Performance using LSTM')\n",
        "\t#plt.subplot(132)\n",
        "\t#plt.plot(look_back,mse[1,:],label='Including pollution')\n",
        "\t#plt.xlabel('Number of lookbacks')\n",
        "\t#plt.ylabel('RMSE')\n",
        "\t#plt.legend()\n",
        "\t#plt.grid()\n",
        "\t#---------------------------------------------------------\n",
        "\t#plt.title('Performance using GRU')\n",
        "\t#plt.subplot(133)\n",
        "\t#plt.plot(look_back,mse[2,:],label='Including pollution')\n",
        "\t#plt.xlabel('Number of lacks')\n",
        "\t#plt.ylabel('RMSE')\n",
        "\t#plt.legend()\n",
        "\t#plt.grid()\n",
        "\t#plt.title('Performance using RNN')\n",
        "\tplt.show()\n",
        "\n",
        "def DataPreparation_TimesAhead(MVSeries,look_back,n_steps_ahead,create_datasetMV_TimesAhead):\n",
        "\tgroups = [0, 1, 2, 3, 5, 6, 7]\n",
        "\ttimes = MVSeries.shape[0]\n",
        "    # split into train and test sets\n",
        "\ttrain_size = int(times * 0.67)\n",
        "\ttest_size = times - train_size\n",
        "\ttrain, test = MVSeries[0:train_size,groups], MVSeries[train_size-look_back:times,groups]\n",
        "    # normalize the dataset\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\ttrainN = scaler.fit_transform(train)\n",
        "\ttestN = scaler.transform(test)\n",
        "\tX_train, y_train = create_datasetMV_TimesAhead(trainN, look_back=look_back,n_steps_ahead=n_steps_ahead)\n",
        "\tX_test, y_test = create_datasetMV_TimesAhead(testN, look_back=look_back,n_steps_ahead=n_steps_ahead)\n",
        "    # Defino un scaler sólo para polución\n",
        "\tscaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\tscaler.fit(train[:,0].reshape(-1,1))\n",
        "\treturn X_train, y_train, X_test, y_test, scaler\n",
        "\n",
        "def Plot_sentiment_performance(sensitivity,accuracy,especificity):\n",
        "\tfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n",
        "\tX = np.arange(3)\n",
        "\tax1.bar(X + 0.00, accuracy[0,:], color = 'b', width = 0.25)\n",
        "\tax1.bar(X + 0.25, accuracy[1,:], color = 'g', width = 0.25)\n",
        "\tax1.bar(X + 0.50, accuracy[2,:], color = 'r', width = 0.25)\n",
        "\tax1.set_xticks([0.25, 1.25, 2.25])\n",
        "\tax1.set_xticklabels(['32','64', '128'])\n",
        "\tax1.set_title('Accuracy')\n",
        "\tax1.set_xlabel('Embedding dimension')\n",
        "\tax2.bar(X + 0.00, sensitivity[0,:], color = 'b', width = 0.25)\n",
        "\tax2.bar(X + 0.25, sensitivity[1,:], color = 'g', width = 0.25)\n",
        "\tax2.bar(X + 0.50, sensitivity[2,:], color = 'r', width = 0.25)\n",
        "\tax2.set_xticks([0.25, 1.25, 2.25])\n",
        "\tax2.set_xticklabels(['32','64', '128'])\n",
        "\tax2.set_title('Sensitivity')\n",
        "\tax2.set_xlabel('Embedding dimension')\n",
        "\tax3.bar(X + 0.00, especificity[0,:], color = 'b', width = 0.25)\n",
        "\tax3.bar(X + 0.25, especificity[1,:], color = 'g', width = 0.25)\n",
        "\tax3.bar(X + 0.50, especificity[2,:], color = 'r', width = 0.25)\n",
        "\tax3.set_xticks([0.25, 1.25, 2.25])\n",
        "\tax3.set_xticklabels(['32','64', '128'])\n",
        "\tax3.set_title('Especificity')\n",
        "\tax3.set_xlabel('Embedding dimension')\n",
        "\tax3.legend(labels=['32 cells','64 cells','128 cells'],bbox_to_anchor=(1.1, 1.05))\n",
        "\tplt.show()\n",
        "\tprint('Best accuracy= {}'.format(np.max(accuracy)))\n",
        "\n",
        "def preprocessed_seq(text_list):\n",
        "\n",
        "    max_fatures = 2001\n",
        "    tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "    tokenizer.fit_on_texts(text_list)\n",
        "    X = tokenizer.texts_to_sequences(text_list)\n",
        "    NewX = pad_sequences(sequences=X, padding=\"post\", value=0)\n",
        "    return tokenizer, NewX"
      ]
    }
  ]
}